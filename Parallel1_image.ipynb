{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outdoor-physiology",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "together-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "import re\n",
    "min_confidence = 0.2\n",
    "size = 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-playlist",
   "metadata": {},
   "source": [
    "## for renaming the file (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "path = './images/'\n",
    "i = 0\n",
    "for filename in os.listdir(path):\n",
    "    os.rename(os.path.join(path,filename), os.path.join(path,'image_'+str(i)+'.jpg'))\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-numbers",
   "metadata": {},
   "source": [
    "## class define and model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "attached-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "    \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "    \"sofa\", \"train\", \"tvmonitor\"]\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(\"MobileNetSSD_deploy.prototxt.txt\", \"MobileNetSSD_deploy.caffemodel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-salad",
   "metadata": {},
   "source": [
    "## function for detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fluid-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(img,q):\n",
    "    #image load\n",
    "    image = cv2.imread(img)\n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "    index = re.sub(\"\\D\", \"\", img)\n",
    "    q.put([blob,image,index])\n",
    "    return None\n",
    "\n",
    "def detect(queue):\n",
    "\n",
    "    arr, image, num = queue.get()\n",
    "    (h, w) = image.shape[:2]\n",
    "    #load image in model\n",
    "    net.setInput(arr)\n",
    "    detections = net.forward()\n",
    "\n",
    "    #look for match in image\n",
    "    for i in np.arange(0, detections.shape[2]):\n",
    "\n",
    "        #extract confidence from detected object\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        #filter out low confidence objects\n",
    "        if confidence > min_confidence:\n",
    "\n",
    "            idx = int(detections[0, 0, i, 1])\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # display the prediction\n",
    "            label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
    "#             print(\"[INFO] {}\".format(label))\n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY), COLORS[idx], 2)\n",
    "\n",
    "            y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "            cv2.putText(image, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n",
    "\n",
    "    # show the output image\n",
    "    cv2.imwrite(\"./outpu/{}_output.jpg\".format(num), image)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-defeat",
   "metadata": {},
   "source": [
    "# Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interpreted-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "qw = [\"./images/image_{}.jpg\".format(i) for i in range(size)]\n",
    "m = mp.Manager()\n",
    "q = m.Queue(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-lounge",
   "metadata": {},
   "source": [
    "## Parallel with 5 processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "impressed-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_prep(qw,q,a,b):\n",
    "    for i in range(a,b):\n",
    "        prep(qw[i],q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "another-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_detect(q,a,b):\n",
    "    for i in range(a,b):\n",
    "        detect(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "capable-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def smap(f):\n",
    "    return f()\n",
    "\n",
    "k = size #no of images\n",
    "\n",
    "prep1 = functools.partial(parallel_prep, qw, q, 0, k//2)\n",
    "prep2 = functools.partial(parallel_prep, qw, q, k//2, k)\n",
    "dete1 = functools.partial(parallel_detect, q, 0, k//3)\n",
    "dete2 = functools.partial(parallel_detect, q, k//3, 2*(k//3))\n",
    "dete3 = functools.partial(parallel_detect, q, 2*(k//3), k)\n",
    "pool = Pool(processes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "indian-artist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Parallel Implementation of 6000 images\n",
      "using 1 processor for preprocessing and 1 processor for detection\n",
      "\n",
      "CPU times: user 12.1 ms, sys: 13.6 ms, total: 25.7 ms\n",
      "Wall time: 6min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"           Parallel Implementation of 6000 images\")\n",
    "print(\"using 1 processor for preprocessing and 1 processor for detection\\n\")\n",
    "res = pool.map_async(smap, [prep1, dete1])\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dutch-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Parallel Implementation of 6000 images\n",
      "using 1 processor for preprocessing and 2 processors for detection\n",
      "\n",
      "CPU times: user 13.4 ms, sys: 8.26 ms, total: 21.7 ms\n",
      "Wall time: 3min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"           Parallel Implementation of 6000 images\")\n",
    "print(\"using 1 processor for preprocessing and 2 processors for detection\\n\")\n",
    "res = pool.map_async(smap, [prep1, dete1, dete2])\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expired-firewall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Parallel Implementation of 6000 images\n",
      "using 2 processor for preprocessing and 2 processors for detection\n",
      "\n",
      "CPU times: user 22.5 ms, sys: 4 ms, total: 26.5 ms\n",
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"           Parallel Implementation of 6000 images\")\n",
    "print(\"using 2 processor for preprocessing and 2 processors for detection\\n\")\n",
    "res = pool.map_async(smap, [prep1, prep2, dete1, dete2])\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tender-laptop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Parallel Implementation of 6000 images\n",
      "using 2 processor for preprocessing and 3 processors for detection\n",
      "\n",
      "CPU times: user 21.9 ms, sys: 7.18 ms, total: 29.1 ms\n",
      "Wall time: 3min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"           Parallel Implementation of 6000 images\")\n",
    "print(\"using 2 processor for preprocessing and 3 processors for detection\\n\")\n",
    "res = pool.map_async(smap, [prep1, prep2, dete1, dete2, dete3])\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "framed-maker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Parallel Implementation of 6000 images\n",
      "using 3 processor for preprocessing and 2 processors for detection\n",
      "\n",
      "CPU times: user 20 ms, sys: 10.2 ms, total: 30.2 ms\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"           Parallel Implementation of 6000 images\")\n",
    "print(\"using 3 processor for preprocessing and 2 processors for detection\\n\")\n",
    "res = pool.map_async(smap, [prep1, prep2, prep3, dete1, dete2])\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "noticed-hostel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Parallel Implementation of 6000 images\n",
      "using 2 processor for preprocessing and 1 processors for detection\n",
      "\n",
      "CPU times: user 16.7 ms, sys: 2.94 ms, total: 19.7 ms\n",
      "Wall time: 4min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"           Parallel Implementation of 6000 images\")\n",
    "print(\"using 2 processor for preprocessing and 1 processors for detection\\n\")\n",
    "res = pool.map_async(smap, [prep1, prep2, dete1])\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "electronic-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(q.empty() != True):\n",
    "    q.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "brown-embassy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.qsize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
